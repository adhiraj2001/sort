{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0b6e71-6111-4e07-9771-3ab329229bd1",
   "metadata": {},
   "source": [
    "# Object Tracing using SORT and YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7aab49-88fa-4342-a1b6-40046236bdb8",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e352021-a22a-4e36-bcde-68c8e4f75c8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Extracting Frames from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f98d424-a443-43db-9126-b6c580a66042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e91889-1c79-4ddf-90e7-cd70cf6eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(IMG_PATH):\n",
    "    os.makedirs(IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b72ebaf-dded-429e-bc80-46684879bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(f'./Data/videos/{FILE_NAME}.mp4')\n",
    "success, image = vidcap.read()\n",
    "\n",
    "count = 0\n",
    "while success:\n",
    "    if count == 10:\n",
    "        break\n",
    "    \n",
    "    # cv2.imwrite(f\"{IMG_PATH}/frame_{int(count)}.png\", image) # save frame as PNG file      \n",
    "    cv2.imwrite(f\"{IMG_PATH}/frame_{int(count)}.jpg\", image) # save frame as JPG file      \n",
    "    \n",
    "    ## Clearing Memory\n",
    "    del image # does it make a difference though ?\n",
    "    gc.collect()\n",
    "    \n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    # print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b2f774-54e4-4e81-b6be-c55ead23d936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clearing Memory\n",
    "del vidcap # doesn't make a lot of difference i think since it's just a object\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d99f1ef-6306-4c15-b8fc-f9fbe07ac63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset Kernel\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e17eb0-d33e-44a0-9647-5027ceecfc90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Running Detector on the video / image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256f867a-c671-4796-ad0f-c75dac3400bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8870ed80-c9be-4479-ad5c-f11cd09d3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(IMG_PATH):\n",
    "    os.makedirs(IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3121e652-c65d-49d3-9f27-450f19630e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23b24bc-c735-48cd-8331-f2cad6e1e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "    # for filename in os.scandir(folder):\n",
    "        # if filename.is_dir(): # only available for scandir files\n",
    "        #     continue\n",
    "            \n",
    "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            \n",
    "            if img is not None:\n",
    "                images.append(img[..., ::-1])\n",
    "                \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83288377-4d79-4eac-8110-c3c6aeac577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PRETRAIN_WEIGHT = 'yolov5m6'\n",
    "\n",
    "PRETRAIN_WEIGHT = 'custom'\n",
    "WEIGHT_PATH = './pretrained_weights/yolov5m6.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d44048-a630-4c3f-8350-a0549868f590",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Using Pytorch Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97b47e96-edd1-4975-aba9-f257facd2249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/adhiraj/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-12-8 Python-3.10.8 torch-1.13.0 CUDA:0 (NVIDIA GeForce GTX 1650, 3912MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m6 summary: 378 layers, 35704908 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=1, trust_repo=True) # only predict persons class\n",
    "# model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, path=WEIGHT_PATH, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "\n",
    "# model.load_state_dict(torch.load('yolov5s_10cls.pt')['model'].state_dict())\n",
    "model.to(DEVICE)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04fed28e-6280-4660-b263-8c6bee30b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Mode\n",
    "model.eval()\n",
    "\n",
    "# model.conf = 0.25  # NMS confidence threshold\n",
    "model.conf = 0.1  # NMS confidence threshold\n",
    "\n",
    "# model.iou = 0.45  # NMS IoU threshold\n",
    "model.iou = 0.1  # NMS IoU threshold\n",
    "\n",
    "model.agnostic = False # NMS class-agnostic (means will detect objects even when no classes ?)\n",
    "model.multi_label = False  # NMS multiple labels per box\n",
    "\n",
    "# model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "model.classes = [0]\n",
    "\n",
    "model.max_det = 1000  # maximum number of detections per image\n",
    "model.amp = False  # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e897160-2453-4062-9636-d3bae2bb335e",
   "metadata": {},
   "source": [
    "**Loading individually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c127b446-d258-4c70-a3db-a68c213c726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Images from Directory\n",
    "images = load_images_from_folder(folder=IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ee3ed9e-4f03-40bc-b6e5-25718ff1e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = os.path.join('./Results', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc1f42d-575a-4f58-841e-6bd817c6b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mResults/images/test12\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test13\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test14\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test15\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test16\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test17\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test18\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test19\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test110\u001b[0m\n",
      "Saved 1 image to \u001b[1mResults/images/test111\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Saving Individually\n",
    "\n",
    "coordinates = []\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # results = model(img, size=640) # batch of images\n",
    "        results = model(img, size=1280) # batch of images\n",
    "    \n",
    "    ## Results\n",
    "    # results.print()\n",
    "    \n",
    "    # results.save()\n",
    "    # results.save(save_dir=f\"{RESULT_PATH}/frame_{int(i)}.png\")  # or .show()\n",
    "    results.save(save_dir=f\"{RESULT_PATH}\")  # or .show()\n",
    "    \n",
    "    coordinates.append(results.xyxy[0].detach().cpu().numpy()[..., :4])\n",
    "    \n",
    "    del results\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# print(results.xyxy[0])  # print img1 predictions (Bounding Box pixels) \n",
    "#                   x1           y1           x2           y2   confidence        class\n",
    "# tensor([[7.50637e+02, 4.37279e+01, 1.15887e+03, 7.08682e+02, 8.18137e-01, 0.00000e+00],\n",
    "#         [9.33597e+01, 2.07387e+02, 1.04737e+03, 7.10224e+02, 5.78011e-01, 0.00000e+00],\n",
    "#         [4.24503e+02, 4.29092e+02, 5.16300e+02, 7.16425e+02, 5.68713e-01, 2.70000e+01]])\n",
    "\n",
    "# print()\n",
    "# display(results.pandas().xyxy[0])  # img predictions (pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822069f-f142-4a74-9737-cfa1a16d821d",
   "metadata": {},
   "source": [
    "**Loading in Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "557032e7-ebbe-459d-8ea1-d1feb5409a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can also send images in a BATCH\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # results = model(images, size=640) # batch of images\n",
    "#     results = model(images, size=1280) # batch of images\n",
    "\n",
    "# # Results\n",
    "# results.print()\n",
    "# # results.save()\n",
    "# results.save(save_dir=f\"{RESULT_PATH}/run\")  # or .show()\n",
    "# # results.show()\n",
    "\n",
    "# display(results.pandas().xyxy[0])  # img predictions (pandas)\n",
    "\n",
    "# coordinates = np.array(results.xyxy)\n",
    "# coordinates = [x.detach().cpu().numpy() for x in coordinates]\n",
    "\n",
    "# del results\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # print(results.xyxy[0])  # print img1 predictions (Bounding Box pixels) \n",
    "# #                   x1           y1           x2           y2   confidence        class\n",
    "# # tensor([[7.50637e+02, 4.37279e+01, 1.15887e+03, 7.08682e+02, 8.18137e-01, 0.00000e+00],\n",
    "# #         [9.33597e+01, 2.07387e+02, 1.04737e+03, 7.10224e+02, 5.78011e-01, 0.00000e+00],\n",
    "# #         [4.24503e+02, 4.29092e+02, 5.16300e+02, 7.16425e+02, 5.68713e-01, 2.70000e+01]])\n",
    "\n",
    "# # print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38bfe1-3dd2-459a-a785-cc47589489bc",
   "metadata": {},
   "source": [
    "**Save coordinates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fea45785-5079-45ac-9810-c76badbf0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = os.path.join('./Results', 'coordinates', f'{FILE_NAME}')\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae503a8-5e8e-4af7-8beb-07dc043f7fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coordinates)):\n",
    "    # np.savetxt(f'{RESULT_PATH}/frame_{i}.txt', results.xyxy[i].detach().cpu().numpy()[..., :4], fmt='%.4f')\n",
    "    \n",
    "    # np.savetxt(f'{RESULT_PATH}/frame_{i}.txt', coordinates[i], fmt='%d', delimiter=',', newline='\\n')\n",
    "    np.savetxt(f'{RESULT_PATH}/frame_{i}.txt', coordinates[i], fmt='%0.2f', delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10574059-e22d-4007-99b4-f8ee3320781f",
   "metadata": {},
   "source": [
    "#### Cloning YOLOv5 repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd516859-bc84-4dc2-b0ce-df1ef612ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sort]",
   "language": "python",
   "name": "conda-env-sort-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
