{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0b6e71-6111-4e07-9771-3ab329229bd1",
   "metadata": {},
   "source": [
    "# Object Tracing using SORT and YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7aab49-88fa-4342-a1b6-40046236bdb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e352021-a22a-4e36-bcde-68c8e4f75c8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting Frames from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f98d424-a443-43db-9126-b6c580a66042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5772395-d0fd-4340-912f-bfcc5e8766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e91889-1c79-4ddf-90e7-cd70cf6eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "VID_PATH = os.path.join('./Data', 'videos', f'{FILE_NAME}')\n",
    "if not os.path.exists(VID_PATH):\n",
    "    os.makedirs(VID_PATH)\n",
    "\n",
    "# IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "# if not os.path.exists(IMG_PATH):\n",
    "#     os.makedirs(IMG_PATH)\n",
    "\n",
    "RESULT_PATH = os.path.join('./Results', 'coordinates', f'{FILE_NAME}')\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4940a58f-ca78-48a7-8099-1f4ea57ef3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PRETRAIN_WEIGHT = 'yolov5m6'\n",
    "\n",
    "PRETRAIN_WEIGHT = 'custom'\n",
    "WEIGHT_PATH = './pretrained_weights/yolov5m6.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2100b62-5160-4769-8f43-850ed3475046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/adhiraj/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-12-8 Python-3.10.8 torch-1.13.0 CUDA:0 (NVIDIA GeForce GTX 1650, 3912MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m6 summary: 378 layers, 35704908 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=1, trust_repo=True) # only predict persons class\n",
    "# model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, path=WEIGHT_PATH, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "\n",
    "# model.load_state_dict(torch.load('yolov5s_10cls.pt')['model'].state_dict())\n",
    "model.to(DEVICE)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8929c993-f525-40cc-8493-1e577805748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Modej\n",
    "model.eval()\n",
    "\n",
    "# model.conf = 0.25  # NMS confidence threshold\n",
    "model.conf = 0.10  # NMS confidence threshold\n",
    "\n",
    "# model.iou = 0.45  # NMS IoU threshold\n",
    "model.iou = 0.30  # NMS IoU threshold\n",
    "\n",
    "model.agnostic = False # NMS class-agnostic (means will detect objects even when no classes ?)\n",
    "model.multi_label = False  # NMS multiple labels per box\n",
    "\n",
    "# model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "model.classes = [0]\n",
    "\n",
    "model.max_det = 1000  # maximum number of detections per image\n",
    "model.amp = False  # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b72ebaf-dded-429e-bc80-46684879bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(f'{VID_PATH}.mp4')\n",
    "success, image = vidcap.read()\n",
    "\n",
    "count = 0\n",
    "while success:\n",
    "    if count == 100:\n",
    "        break\n",
    "    \n",
    "    # cv2.imwrite(f\"{IMG_PATH}/frame_{int(count)}.jpg\", image) # save frame as JPG file\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        results = model(image, size=1280) # batch of images\n",
    "        \n",
    "    coordinates = results.xyxy[0].detach().cpu().numpy()[..., :5]\n",
    "    \n",
    "    np.savetxt(f'{RESULT_PATH}/frame_{count}.txt', coordinates, fmt='%0.2f', delimiter=',', newline='\\n')\n",
    "    \n",
    "    \n",
    "    ## Clearing Memory\n",
    "    del results\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    del coordinates\n",
    "    del image # does it make a difference though ?\n",
    "    gc.collect()\n",
    "    \n",
    "    ## Reading Next Frame\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    # print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b2f774-54e4-4e81-b6be-c55ead23d936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clearing Memory\n",
    "\n",
    "del vidcap # doesn't make a lot of difference i think since it's just a object\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d99f1ef-6306-4c15-b8fc-f9fbe07ac63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset Kernel\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ad4e9f-54a1-495c-b0e7-555a4a966464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# from skimage import io\n",
    "\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c6d64f2-0c41-4975-b319-c01b57faaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17d2b92-0e44-4d40-b5b1-2fc91e444e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "VID_PATH = os.path.join('./Data', 'videos', f'{FILE_NAME}')\n",
    "\n",
    "if not os.path.exists(VID_PATH):\n",
    "    print(f'ERROR: {VID_PATH} Folder not found!')\n",
    "    exit()\n",
    "\n",
    "# IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "# if not os.path.exists(IMG_PATH):\n",
    "#     os.makedirs(IMG_PATH)\n",
    "\n",
    "RESULT_PATH = os.path.join('./Results', 'coordinates', f'{FILE_NAME}')\n",
    "\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    print(f'ERROR: {RESULT_PATH} Folder not found!')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21212d3c-0569-4632-8a2e-99cf2a7a2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "    \n",
    "# display = args.display\n",
    "# phase = args.phase\n",
    "\n",
    "# total_time = 0.0\n",
    "# total_frames = 0\n",
    "\n",
    "colours = np.random.rand(32, 3) #used only for display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd413e2-3927-4edd-95bb-818895ce6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111, aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3cf15a-3aa9-41e2-87e1-187a7c3499cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_age = 1\n",
    "min_hits = 3\n",
    "iou_threshold = 0.3\n",
    "\n",
    "mot_tracker = Sort(max_age=max_age, \n",
    "                   min_hits=min_hits, \n",
    "                   iou_threshold=iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156424a5-e3ba-45b6-aef6-8b606440f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(f'{VID_PATH}.mp4')\n",
    "success, image = vidcap.read()\n",
    "\n",
    "count = 0\n",
    "while success:\n",
    "    if count == 100:\n",
    "        break\n",
    "    \n",
    "    frame = os.path.join(RESULT_PATH, f'frame_{count}.txt')\n",
    "    dets = np.loadtxt(frame, delimiter=',')\n",
    "    \n",
    "    # dets[:, 2:4] += dets[:, 0:2] # don't need to do this\n",
    "    \n",
    "    ax1.imshow(image)\n",
    "    plt.title(FILE_NAME + ' Tracked Targets')\n",
    "    \n",
    "    # start_time = time.time()\n",
    "    \n",
    "    trackers = mot_tracker.update(dets)\n",
    "    \n",
    "    # cycle_time = time.time() - start_time\n",
    "    # total_time += cycle_time\n",
    "    \n",
    "    for d in trackers:\n",
    "        # print('%d,%d,%.2f,%.2f,%.2f,%.2f,1,-1,-1,-1'%(frame,d[4],d[0],d[1],d[2]-d[0],d[3]-d[1]),file=out_file)\n",
    "        \n",
    "        d = d.astype(np.int32)\n",
    "        ax1.add_patch(patches.Rectangle((d[0], d[1]), d[2] - d[0], d[3] - d[1], fill=False, lw=1, ec=colours[d[4]%32, :]))\n",
    "        \n",
    "    fig.canvas.flush_events()\n",
    "    plt.draw()\n",
    "    ax1.cla()\n",
    "    \n",
    "    del trackers\n",
    "    del dets\n",
    "    del frame\n",
    "    del image # does it make a difference though ?\n",
    "    gc.collect()\n",
    "    \n",
    "    ## Reading Next Frame\n",
    "    success, image = vidcap.read()\n",
    "    \n",
    "    # print('Read a new frame: ', success)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3779e1d5-5b12-4aeb-a4eb-ad4d296e26fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fbefc2339d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close(fig)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f002ae-5440-4a67-9f15-5f2017f88ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del vidcap\n",
    "del ax1\n",
    "del fig\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192b1a0-126b-47d2-9bd0-07c9c2514244",
   "metadata": {},
   "source": [
    "**Command to convert Video to Image Frames:**\n",
    "\n",
    "%command: `ffmpeg -i test1.mp4 -f image2 test_frames/img_%04d.jpg`\n",
    "\n",
    "More info: https://ffmpeg.org/ffmpeg.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sort]",
   "language": "python",
   "name": "conda-env-sort-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
