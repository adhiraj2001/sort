{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0b6e71-6111-4e07-9771-3ab329229bd1",
   "metadata": {},
   "source": [
    "# Object Tracing using SORT and YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e352021-a22a-4e36-bcde-68c8e4f75c8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting Frames from videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192b1a0-126b-47d2-9bd0-07c9c2514244",
   "metadata": {},
   "source": [
    "**Command to convert Video to Image Frames:**\n",
    "\n",
    "%command: `ffmpeg -i test1.mp4` (to get details about the video)\n",
    "%command: `ffmpeg -i test1.mp4 -f image2 test_frames/img_%04d.jpg` (extract frames)\n",
    "\n",
    "More info: \n",
    "- https://ffmpeg.org/ffmpeg.html\n",
    "- https://www.bannerbear.com/blog/how-to-extract-images-from-a-video-using-ffmpeg/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad4ac6-565f-4416-883e-35933341a0b6",
   "metadata": {},
   "source": [
    "### Extracting coordinates of Detections from each Video Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f98d424-a443-43db-9126-b6c580a66042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5772395-d0fd-4340-912f-bfcc5e8766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e91889-1c79-4ddf-90e7-cd70cf6eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(IMG_PATH):\n",
    "    os.makedirs(IMG_PATH)\n",
    "\n",
    "OUTPUT_PATH = os.path.join('./Output', 'coordinates', f'{FILE_NAME}')\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4940a58f-ca78-48a7-8099-1f4ea57ef3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# PRETRAIN_WEIGHT = 'yolov5m6'\n",
    "\n",
    "PRETRAIN_WEIGHT = 'custom'\n",
    "WEIGHT_PATH = './pretrained_weights/yolov5m6.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2100b62-5160-4769-8f43-850ed3475046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/adhiraj/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-12-8 Python-3.10.8 torch-1.13.0 CUDA:0 (NVIDIA GeForce GTX 1650, 3912MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m6 summary: 378 layers, 35704908 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes=1, trust_repo=True) # only predict persons class\n",
    "# model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "model = torch.hub.load('ultralytics/yolov5', PRETRAIN_WEIGHT, path=WEIGHT_PATH, device=DEVICE, trust_repo=True)  # load on DEVICE = CUDA/CPU\n",
    "\n",
    "# model.load_state_dict(torch.load('yolov5s_10cls.pt')['model'].state_dict())\n",
    "model.to(DEVICE)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8929c993-f525-40cc-8493-1e577805748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Modej\n",
    "model.eval()\n",
    "\n",
    "# model.conf = 0.25  # NMS confidence threshold\n",
    "model.conf = 0.1 # NMS confidence threshold\n",
    "\n",
    "# model.iou = 0.45  # NMS IoU threshold\n",
    "model.iou = 0.3  # NMS IoU threshold\n",
    "\n",
    "model.agnostic = False # NMS class-agnostic (means will detect objects even when no classes ?)\n",
    "model.multi_label = False  # NMS multiple labels per box\n",
    "\n",
    "# model.classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n",
    "model.classes = [0]\n",
    "\n",
    "model.max_det = 1000  # maximum number of detections per image\n",
    "model.amp = False  # Automatic Mixed Precision (AMP) inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037625c9-caf1-4008-a72d-277e74dfd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(IMG_PATH) # your directory path\n",
    "n_img = len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c96a47-b8b2-454c-bf61-43afa357f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_img + 1):\n",
    "    if i == 101:\n",
    "        break\n",
    "    \n",
    "    img_path = os.path.join(IMG_PATH, f'frame_{i:04d}.jpg')\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is not None:\n",
    "        img = img[..., ::-1]\n",
    "    else:\n",
    "        print(f'path: {img_path} does not have img.')\n",
    "        exit()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # results = model(img, size=1280) # batch of img \n",
    "        results = model(img, size=1920) # batch of img \n",
    "        \n",
    "    coordinates = results.xyxy[0].detach().cpu().numpy()[..., :5]\n",
    "    \n",
    "    np.savetxt(f'{OUTPUT_PATH}/frame_{i:04d}.txt', coordinates, fmt='%0.2f', delimiter=',', newline='\\n')\n",
    "    \n",
    "    \n",
    "    ## Clearing Memory\n",
    "    del results\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    del img_path \n",
    "    del coordinates\n",
    "    del img # does it make a difference though ?\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d99f1ef-6306-4c15-b8fc-f9fbe07ac63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset Kernel\n",
    "\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f788267-15c5-4952-bee7-7891a8164281",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exiting cuz running the below part from python file\n",
    "\n",
    "# exit()\n",
    "# raise SystemExit(\"Stop right there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773cb4c-e6cd-4a5c-80b2-397c7d51b782",
   "metadata": {},
   "source": [
    "### Using SORT Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ad4e9f-54a1-495c-b0e7-555a4a966464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# from skimage import io\n",
    "\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6d64f2-0c41-4975-b319-c01b57faaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort import Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e17d2b92-0e44-4d40-b5b1-2fc91e444e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test1'\n",
    "\n",
    "IMG_PATH = os.path.join('./Data', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(IMG_PATH):\n",
    "    os.makedirs(IMG_PATH)\n",
    "\n",
    "OUTPUT_PATH = os.path.join('./Output', 'coordinates', f'{FILE_NAME}')\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "    \n",
    "OUTPUT_IMG_PATH = os.path.join('./Output', 'images', f'{FILE_NAME}')\n",
    "if not os.path.exists(OUTPUT_IMG_PATH):\n",
    "    os.makedirs(OUTPUT_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21212d3c-0569-4632-8a2e-99cf2a7a2d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "    \n",
    "# display = args.display\n",
    "# phase = args.phase\n",
    "\n",
    "# total_time = 0.0\n",
    "# total_frames = 0\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "## selecting colors for bounding box\n",
    "# 1\n",
    "# colors = np.random.rand(32, 3)\n",
    "\n",
    "# 2\n",
    "cmap = plt.get_cmap('tab20b')\n",
    "colors = np.array([cmap(i)[:3] for i in np.linspace(0, 1, 20)]) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c3cf15a-3aa9-41e2-87e1-187a7c3499cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_age = 1\n",
    "min_hits = 3\n",
    "iou_threshold = 0.3\n",
    "\n",
    "mot_tracker = Sort(max_age=max_age, \n",
    "                   min_hits=min_hits, \n",
    "                   iou_threshold=iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd413e2-3927-4edd-95bb-818895ce6979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111, aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db435482-854d-49ff-9f41-1ab42d82c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = os.listdir(IMG_PATH) # your directory path\n",
    "n_img = len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f15f643c-e888-4cb3-9da0-3e655d64e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, n_img + 1):\n",
    "    if i == 101:\n",
    "        break\n",
    "        \n",
    "    img_path = os.path.join(IMG_PATH, f'frame_{i:04d}.jpg')\n",
    "    frame = cv2.imread(img_path)\n",
    "    \n",
    "    if frame is not None:\n",
    "        frame = frame[..., ::-1]\n",
    "    else:\n",
    "        print(f'path: \\'{img_path}\\' does not have img.')\n",
    "        exit()\n",
    "    \n",
    "    coords = os.path.join(OUTPUT_PATH, f'frame_{i:04d}.txt')\n",
    "    dets = np.loadtxt(coords, delimiter=',')\n",
    "    \n",
    "    # dets[:, 2:4] += dets[:, 0:2] # don't need to do this\n",
    "    \n",
    "    ## not using matplot lib\n",
    "    # ax1.imshow(frame)\n",
    "    # plt.title(FILE_NAME + ' Tracked Targets')\n",
    "    \n",
    "    # start_time = time.time()\n",
    "    \n",
    "    trackers = mot_tracker.update(dets)\n",
    "    \n",
    "    # cycle_time = time.time() - start_time\n",
    "    # total_time += cycle_time\n",
    "    \n",
    "    ## Needed to avoid error for some reason\n",
    "    # frame = frame.transpose((1, 2, 0)).astype(np.uint8).copy()\n",
    "    frame = frame.copy()\n",
    "    \n",
    "    \n",
    "    for d in trackers:\n",
    "        # print('%d,%d,%.2f,%.2f,%.2f,%.2f,1,-1,-1,-1'%(frame,d[4],d[0],d[1],d[2]-d[0],d[3]-d[1]),file=out_file)\n",
    "        \n",
    "        d = d.astype(np.int32)\n",
    "        \n",
    "        # cls = classes[int(cls_pred)]\n",
    "        obj_id = int(d[4]) ## instead of class name we are using class\n",
    "        conf_score = float(d[5]) ## confidence score, of our detections\n",
    "        \n",
    "        \n",
    "        # color = colors[int(obj_id) % len(colors)]\n",
    "        color = colors[obj_id % len(colors), :].astype(float)\n",
    "        \n",
    "        ## Selecting color\n",
    "        # 1\n",
    "        # color = (color * 255.0 / (np.max(color) - np.min(color))).astype(int).tolist()\n",
    "        \n",
    "        # 2\n",
    "        color = colors[int(obj_id) % len(colors)].tolist()\n",
    "        # color = [i * 255 for i in color]\n",
    "        \n",
    "        \n",
    "        ## Editing the image itself for inserting bounding box\n",
    "        \n",
    "        # cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h), color, 4)\n",
    "        cv2.rectangle(img = frame, pt1 = (d[0], d[1]), pt2 = (d[2], d[3]), color = color, thickness = 2)\n",
    "        \n",
    "        ## cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60, y1), color, -1)\n",
    "        # cv2.rectangle(img = frame, pt1 = (d[0], d[1] - 35), pt2 = (d[0] + len(str(obj_id)) * 19 + 60, d[1]), color = color, thickness = -1)\n",
    "        \n",
    "        \n",
    "        # frame_text = f'id: {int(obj_id)}'\n",
    "        frame_text = f'id: {int(obj_id)}, conf: {float(conf_score):.2f}'\n",
    "        # cv2.putText(frame, cls + \"-\" + str(int(obj_id)), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 3)\n",
    "        cv2.putText(img = frame, text = frame_text, org = (d[0], d[1] - 10), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.5, color = (255, 255, 255), thickness = 2)\n",
    "        \n",
    "        \n",
    "        ## using Matplot lib to display bounding boxes\n",
    "        # ax1.add_patch(patches.Rectangle((d[0], d[1]), d[2] - d[0], d[3] - d[1], fill=False, lw=1, ec=colors[d[4] % len(colors), :]))\n",
    "    \n",
    "    \n",
    "    ## not using matplotlib\n",
    "    # fig.canvas.flush_events()\n",
    "    # plt.draw()\n",
    "    # ax1.cla()\n",
    "    \n",
    "    \n",
    "    ## saving the image\n",
    "    output_img_path = f'{OUTPUT_IMG_PATH}/frame_{i:04d}.jpg'\n",
    "    # print(f'{output_img_path}: {frame.shape}')\n",
    "    \n",
    "    ## cv2\n",
    "    # compression_params = [int(cv2.IMWRITE_JPEG_QUALITY), 80]\n",
    "    # if not cv2.imwrite(output_img_path, frame, compression_params):\n",
    "    #     raise Exception(\"Could not write image.\")\n",
    "        \n",
    "    if not cv2.imwrite(output_img_path, frame):\n",
    "        raise Exception(\"Could not write image.\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    ## PIL\n",
    "    # im = Image.fromarray(frame)\n",
    "    ## im.save(output_img_path)\n",
    "    # im.save(output_img_path, format='JPEG',quality=50)\n",
    "    \n",
    "    \n",
    "    del trackers\n",
    "    del dets\n",
    "    del coords\n",
    "    del img_path\n",
    "    # del compression_params\n",
    "    del output_img_path\n",
    "    del frame # does it make a difference though ?\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3779e1d5-5b12-4aeb-a4eb-ad4d296e26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not using matplot lib\n",
    "\n",
    "# plt.close(fig)\n",
    "# plt.ioff()\n",
    "\n",
    "# del ax1\n",
    "# del fig\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c0e60bf-00b6-4aea-8b8a-7bc042cc34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reset Kernel\n",
    "\n",
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sort]",
   "language": "python",
   "name": "conda-env-sort-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
